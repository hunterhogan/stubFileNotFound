"""
This type stub file was generated by pyright.
"""

from builtins import *

"""This module implements useful functionality on top of the Index class,
which is not currently present in numpy"""
__author__ = ...
__license__ = ...
__email__ = ...
def count(keys, axis=...): # -> tuple[ndarray[_Shape, dtype[Any]] | tuple[Any, ...], NDArray[Any]]:
    """count the number of times each key occurs in the input set

    Arguments
    ---------
    keys : indexable object

    Returns
    -------
    unique : ndarray, [groups, ...]
        unique keys
    count : ndarray, [groups], int
        the number of times each key occurs in the input set

    Notes
    -----
    Can be seen as numpy work-alike of collections.Counter
    Alternatively, as sparse equivalent of count_table
    """
    ...

def count_table(*keys): # -> tuple[tuple[ndarray[_Shape, dtype[Any]] | tuple[Any, ...], ...], NDArray[Any]]:
    """count the number of times each key occurs in the input set

    Arguments
    ---------
    keys : tuple of indexable objects, each having the same number of items

    Returns
    -------
    unique : tuple of ndarray, [groups, ...]
        unique keys for each input item
        they form the axes labels of the table
    table : ndarray, [keys[0].groups, ... keys[n].groups], int
        the number of times each key-combination occurs in the input set

    Notes
    -----
    Equivalent to R's pivot table or pandas 'crosstab'
    Alternatively, dense equivalent of the count function
    Should we add weights option?
    Or better yet; what about general reductions over key-grids?
    """
    ...

def binning(keys, start, end, count, axes=...): # -> None:
    """Perform binning over the given axes of the keys

    Parameters
    ----------
    keys : indexable or tuple of indexable

    Examples
    --------
    binning(np.random.rand(100), 0, 1, 10)
    """
    ...

class Table:
    """group_by type functionality on dense grids; like a generalized bincount

    add fixed range support?
    Table(ranges).group_by(keys).mean(values)
    Table().count(keys)
    """
    def __init__(self, *keys) -> None:
        ...
    
    def get_inverses(self, keys): # -> tuple[_Array1D[Any] | Any, ...]:
        """
        Returns
        -------
        Tuple of inverse indices
        """
        ...
    
    def allocate(self, dtype, fill=...): # -> NDArray[float64]:
        ...
    
    def count(self): # -> tuple[tuple[ndarray[_Shape, dtype[Any]] | tuple[Any, ...], ...], NDArray[float64]]:
        ...
    
    def sum(self, values): # -> tuple[tuple[ndarray[_Shape, dtype[Any]] | tuple[Any, ...], ...], NDArray[float64]]:
        ...
    
    def mean(self, values): # -> tuple[tuple[ndarray[_Shape, dtype[Any]] | tuple[Any, ...], ...], NDArray[float64]]:
        ...
    
    def first(self, values): # -> tuple[tuple[ndarray[_Shape, dtype[Any]] | tuple[Any, ...], ...], NDArray[float64]]:
        ...
    
    def last(self, values): # -> tuple[tuple[ndarray[_Shape, dtype[Any]] | tuple[Any, ...], ...], NDArray[float64]]:
        ...
    
    def min(self, values, default=...): # -> tuple[tuple[ndarray[_Shape, dtype[Any]] | tuple[Any, ...], ...], NDArray[float64]]:
        ...
    
    def max(self, values, default=...): # -> tuple[tuple[ndarray[_Shape, dtype[Any]] | tuple[Any, ...], ...], NDArray[float64]]:
        ...
    
    def unique(self, values): # -> tuple[tuple[ndarray[_Shape, dtype[Any]] | tuple[Any, ...], ...], NDArray[float64]]:
        """Place each entry in a table, while asserting that each entry occurs once"""
        ...
    


def multiplicity(keys, axis=...): # -> ndarray[_Shape, dtype[Any]]:
    """return the multiplicity of each key, or how often it occurs in the set

    Parameters
    ----------
    keys : indexable object

    Returns
    -------
    ndarray, [keys.size], int
        the number of times each input item occurs in the set
    """
    ...

def rank(keys, axis=...): # -> _Array1D[Any]:
    """where each item is in the pecking order.

    Parameters
    ----------
    keys : indexable object

    Returns
    -------
    ndarray, [keys.size], int
        unique integers, ranking the sorting order

    Notes
    -----
    we should have that index.sorted[index.rank] == keys
    """
    ...

def mode(keys, axis=..., weights=..., return_indices=...): # -> tuple[Any, ndarray[_Shape, dtype[intp]] | Any] | Any:
    """compute the mode, or most frequent occuring key in a set

    Parameters
    ----------
    keys : ndarray, [n_keys, ...]
        input array. elements of 'keys' can have arbitrary shape or dtype
    weights : ndarray, [n_keys], optional
        if given, the contribution of each key to the mode is weighted by the given weights
    return_indices : bool
        if True, return all indices such that keys[indices]==mode holds

    Returns
    -------
    mode : ndarray, [...]
        the most frequently occuring key in the key sequence
    indices : ndarray, [mode_multiplicity], int, optional
        if return_indices is True, all indices such that points[indices]==mode holds
    """
    ...

def sort(keys, axis=...): # -> NDArray[Any]:
    """sort an indexable object and return the sorted keys"""
    ...

def argsort(keys, axis=...): # -> NDArray[intp] | Any:
    """return the indices that will place the keys in sorted order"""
    ...

def searchsorted(keys, axis=..., side=..., sorter=...):
    """to be implemented"""
    ...

def incidence(boundary): # -> ndarray[_Shape, dtype[Any]] | list[NDArray[Any]]:
    """
    given an Nxm matrix containing boundary info between simplices,
    compute indidence info matrix
    not very reusable; should probably not be in this lib
    """
    ...

def all_unique(keys, axis=...): # -> bool | Any:
    """Returns true if all keys are unique"""
    ...

def any_unique(keys, axis=...): # -> numpy.bool[builtins.bool]:
    """returns true if any of the keys is unique"""
    ...

def any_equal(keys, axis=...): # -> bool:
    """return true if any of the keys equals another; or if not all the keys are unique"""
    ...

def all_equal(keys, axis=...): # -> bool:
    """returns true of all keys are equal"""
    ...

def is_uniform(keys, axis=...): # -> bool:
    """returns true if all keys have equal multiplicity"""
    ...

