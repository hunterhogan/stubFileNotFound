"""
This type stub file was generated by pyright.
"""

from dataclasses import dataclass
from types import SimpleNamespace
from typing import Any, Iterator, Mapping
from fontTools.designspaceLib import DesignSpaceDocument
from fontTools.feaLib.variableScalar import VariableScalar
from ufo2ft.featureWriters import BaseFeatureWriter

LOGGER = ...
SIDE1_PREFIX = ...
SIDE2_PREFIX = ...
DIST_ENABLED_SCRIPTS = ...
RTL_BIDI_TYPES = ...
LTR_BIDI_TYPES = ...
AMBIGUOUS_BIDIS = ...
COMMON_SCRIPTS_SET = ...
COMMON_CLASS_NAME = ...
def unicodeBidiType(uv): # -> Literal['R', 'L'] | None:
    """Return "R" for characters with RTL direction, or "L" for LTR (whether
    'strong' or 'weak'), or None for neutral direction.
    """
    ...

def script_direction(script: str) -> str:
    ...

@dataclass(frozen=True, order=False)
class KerningPair:
    __slots__ = ...
    side1: str | tuple[str, ...]
    side2: str | tuple[str, ...]
    value: float | VariableScalar
    def __lt__(self, other: KerningPair) -> bool:
        ...
    
    @property
    def firstIsClass(self) -> bool:
        ...
    
    @property
    def secondIsClass(self) -> bool:
        ...
    
    @property
    def firstGlyphs(self) -> tuple[str, ...]:
        ...
    
    @property
    def secondGlyphs(self) -> tuple[str, ...]:
        ...
    
    @property
    def glyphs(self) -> tuple[str, ...]:
        ...
    


class KernFeatureWriter(BaseFeatureWriter):
    """Generates a kerning feature based on groups and rules contained
    in an UFO's kerning data.

    If the `quantization` argument is given in the filter options, the resulting
    anchors are rounded to the nearest multiple of the quantization value.

    ## Implementation Notes

    The algorithm works like this:

    * Parse GDEF GlyphClassDefinition from UFO features.fea to get the set of
      "Mark" glyphs (this will be used later to decide whether to add
      ignoreMarks flag to kern lookups containing pairs between base and mark
      glyphs).
    * Get the ordered glyphset for the font, for filtering kerning groups and
      kernings that reference unknown glyphs.
    * Determine which scripts the kerning affects (read: "the font most probably
      supports"), to know which lookups to generate later:
        * First, determine the unambiguous script associations for each
          (Unicoded) glyph in the glyphset, as in, glyphs that have a single
          entry for their Unicode script extensions property;
        * then, parse the `languagesystem` statements in the provided feature
          file to add on top.
    * Compile a Unicode cmap from the UFO and a GSUB table from the features so
      far, so we can determine:
        * the script (extensions) for each glyph in the glyphset, including
          glyphs reachable via substitution, using the fontTools subsetter with
          its `closure_glyphs` machinery; the scripts are cut down to the ones
          we think the font supports;
        * and the bidirectionality class, so we can later filter out kerning
          pairs that would mix RTL and LTR glyphs, which will not occur in
          applications. Unicode BiDi classes L, AN and EN are considered L, R
          and AL are considered R.
    * Note: the glyph script determination has the quirk of declaring "Hira" and
      "Kana" scripts as "Hrkt" so that they are considered one script and can be
      kerned against each other.
    * Get the kerning groups from the UFO and filter out glyphs not in the
      glyphset and empty groups. Remember which group a glyph is a member of,
      for kern1 and kern2, so we can later reconstruct per-script groups.
    * Get the bare kerning pairs from the UFO, filtering out pairs with unknown
      groups or glyphs not in the glyphset and (redundant) zero class-to-class
      kernings and optionally quantizing kerning values.
    * Start generating lookups. By default, the ignore marks flag is added to
      each lookup. Kerning pairs that kern bases against marks or marks against
      marks, according to the glyphs' GDEF category, then get split off into a
      second lookup without the ignore marks flag.
    * Go through all kerning pairs and split them up by script, to put them in
      different lookups. This reduces the size of each lookup compared to
      splitting by direction, as previously done. If there are kerning pairs
      with different scripts on each side, these scripts are all kept together
      to allow for cross-script kerning (in implementations that apply it).
      Scripts with different direction are always split.
        * Partition the first and second side of a pair by script and emit only
          those with the same script (e.g. `a` and `b` are both "Latn", `period`
          and `period` are both "Default", but `a` and `a-cy` would mix "Latn"
          and "Cyrl" and are dropped), or those with kerning across them, or
          those that kern an explicit against a "common" or "inherited" script
          (e.g. `a` and `period`).
        * Glyphs can have multiple scripts assigned to them (legitimately, e.g.
          U+0951 DEVANAGARI STRESS SIGN UDATTA, or for random reasons like
          having both `sub h by h.sc` and `sub Etaprosgegrammeni by h.sc;`).
          Only scripts that were determined earlier to be supported by the font
          will be considered. Usually, we will emit pairs where both sides have
          the same script and no splitting is necessary. A glyph can be part of
          both for weird reasons, so we always treat any glyph with a common or
          inherited script as a purely common (not inherited) glyph for
          bucketing purposes. This avoids creating overlapping groups with the
          multi-script glyph in a lookup.
        * Some glyphs may have a script of Zyyy or Zinh but have a disjoint set
          of explicit scripts as their script extension. By looking only at the
          script extension, we treat many of them as being part of an explicit
          script rather than as a common or inherited glyph.
        * Preserve the type of the kerning pair, so class-to-class kerning stays
          that way, even when there's only one glyph on each side.
    * Reconstruct kerning group names for the newly split classes. This is done
      for debuggability; it makes no difference for the final font binary.
        * This first looks at the common lookups and then all others, assigning
          new group names are it goes. A class like `@kern1.A = [A A-cy
          increment]` may be split up into `@kern1.Latn.A = [A]`, `@kern1.Cyrl.A
          = [A-cy]` and `@kern1.Default.A = [increment]`. Note: If there is no
          dedicated Default lookup, common glyph classes like `[period]` might
          carry the name `@kern1.Grek.foo` if the class was first encountered
          while going over the Grek lookup.
    * Discard pairs that mix RTL and LTR BiDi types, because they won't show up
      in applications due to how Unicode text is split into runs.
    * Discard empty lookups, if they were created but all their pairs were
      discarded.
    * Make a `kern` (and potentially `dist`) feature block and register the
      lookups for each script. Some scripts need to be registered in the `dist`
      feature for some shapers to discover them, e.g. Yezi.
    * Write the new glyph class definitions and then the lookups and feature
      blocks to the feature file.
    """
    tableTag = ...
    features = ...
    options = ...
    def setContext(self, font, feaFile, compiler=...): # -> SimpleNamespace:
        ...
    
    def shouldContinue(self): # -> bool:
        ...
    
    def getKerningData(self): # -> SimpleNamespace:
        ...
    
    def getKerningGroups(self) -> tuple[Mapping[str, tuple[str, ...]], Mapping[str, tuple[str, ...]]]:
        ...
    
    def getKerningPairs(self, side1Classes: Mapping[str, tuple[str, ...]], side2Classes: Mapping[str, tuple[str, ...]]) -> list[KerningPair]:
        ...
    
    @staticmethod
    def getVariableKerningPairs(designspace: DesignSpaceDocument, side1Classes: Mapping[str, tuple[str, ...]], side2Classes: Mapping[str, tuple[str, ...]], glyphSet: Mapping[str, str], options: SimpleNamespace) -> list[KerningPair]:
        ...
    
    def knownScriptsPerCodepoint(self, uv: int) -> set[str] | None:
        ...
    


def splitKerning(pairs, glyphScripts): # -> dict[tuple[Any, ...], list[Any]]:
    ...

def partitionByScript(pair: KerningPair, glyphScripts: Mapping[str, set[str]]) -> Iterator[tuple[str, KerningPair]]:
    """Split a potentially mixed-script pair into pairs that make sense based
    on the dominant script, and yield each combination with its dominant script."""
    ...

def mergeScripts(kerningPerScript): # -> dict[tuple[Any, ...], list[Any]]:
    """Merge buckets that have common scripts. If we have [A, B], [B, C], and
    [D] buckets, we want to merge the first two into [A, B, C] and leave [D] so
    that all kerning pairs of the three scripts are in the same lookup."""
    ...

def makeAllGlyphClassDefinitions(kerningPerScript, context, feaFile=...): # -> tuple[dict[Any, Any], dict[Any, Any], dict[Any, Any]]:
    ...

def addClassDefinition(prefix, group, classes, originalMembership, classDefs, classNames, script): # -> None:
    ...

def log_redefined_group(side: str, name: str, group: tuple[str, ...], font: Any, members: set[str]) -> None:
    ...

def log_regrouped_glyph(side: str, name: str, original_name: str, font: Any, member: str) -> None:
    ...

