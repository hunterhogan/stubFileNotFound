from .cudadrv import nvvm as nvvm
from _typeshed import Incomplete
from numba import cuda as cuda
from numba.core import cgutils as cgutils, types as types
from numba.core.datamodel import models as models
from numba.core.imputils import lower_cast as lower_cast, Registry as Registry
from numba.core.typing.npydecl import parse_dtype as parse_dtype
from numba.cuda import errors as errors, nvvmutils as nvvmutils, stubs as stubs
from numba.cuda.types import CUDADispatcher as CUDADispatcher, dim3 as dim3
from numba.np import ufunc_db as ufunc_db
from numba.np.npyimpl import register_ufuncs as register_ufuncs

registry: Incomplete
lower: Incomplete
lower_attr: Incomplete
lower_constant: Incomplete

def initialize_dim3(builder, prefix): ...
def cuda_threadIdx(context, builder, sig, args): ...
def cuda_blockDim(context, builder, sig, args): ...
def cuda_blockIdx(context, builder, sig, args): ...
def cuda_gridDim(context, builder, sig, args): ...
def cuda_laneid(context, builder, sig, args): ...
def dim3_x(context, builder, sig, args): ...
def dim3_y(context, builder, sig, args): ...
def dim3_z(context, builder, sig, args): ...
def cuda_const_array_like(context, builder, sig, args): ...

_unique_smem_id: int

def _get_unique_smem_id(name):
    """Due to bug with NVVM invalid internalizing of shared memory in the
    PTX output.  We can't mark shared memory to be internal. We have to
    ensure unique name is generated for shared memory symbol.
    """
def cuda_shared_array_integer(context, builder, sig, args): ...
def cuda_shared_array_tuple(context, builder, sig, args): ...
def cuda_local_array_integer(context, builder, sig, args): ...
def ptx_lmem_alloc_array(context, builder, sig, args): ...
def ptx_threadfence_block(context, builder, sig, args): ...
def ptx_threadfence_system(context, builder, sig, args): ...
def ptx_threadfence_device(context, builder, sig, args): ...
def ptx_syncwarp(context, builder, sig, args): ...
def ptx_syncwarp_mask(context, builder, sig, args): ...
def ptx_shfl_sync_i32(context, builder, sig, args):
    """
    The NVVM intrinsic for shfl only supports i32, but the cuda intrinsic
    function supports both 32 and 64 bit ints and floats, so for feature parity,
    i64, f32, and f64 are implemented. Floats by way of bitcasting the float to
    an int, then shuffling, then bitcasting back. And 64-bit values by packing
    them into 2 32bit values, shuffling thoose, and then packing back together.
    """
def ptx_vote_sync(context, builder, sig, args): ...
def ptx_match_any_sync(context, builder, sig, args): ...
def ptx_match_all_sync(context, builder, sig, args): ...
def ptx_activemask(context, builder, sig, args): ...
def ptx_lanemask_lt(context, builder, sig, args): ...
def ptx_popc(context, builder, sig, args): ...
def ptx_fma(context, builder, sig, args): ...
def float16_float_ty_constraint(bitwidth): ...
def float16_to_float_cast(context, builder, fromty, toty, val): ...
def float_to_float16_cast(context, builder, fromty, toty, val): ...
def float16_int_constraint(bitwidth): ...
def float16_to_integer_cast(context, builder, fromty, toty, val): ...
def integer_to_float16_cast(context, builder, fromty, toty, val): ...
def lower_fp16_binary(fn, op): ...
def ptx_fp16_hneg(context, builder, sig, args): ...
def operator_hneg(context, builder, sig, args): ...
def ptx_fp16_habs(context, builder, sig, args): ...
def operator_habs(context, builder, sig, args): ...
def ptx_hfma(context, builder, sig, args): ...
def fp16_div_impl(context, builder, sig, args): ...

_fp16_cmp: str

def _gen_fp16_cmp(op): ...
def lower_fp16_minmax(fn, fname, op): ...

cbrt_funcs: Incomplete

def ptx_cbrt(context, builder, sig, args): ...
def ptx_brev_u4(context, builder, sig, args): ...
def ptx_brev_u8(context, builder, sig, args): ...
def ptx_clz(context, builder, sig, args): ...
def ptx_ffs_32(context, builder, sig, args): ...
def ptx_ffs_64(context, builder, sig, args): ...
def ptx_selp(context, builder, sig, args): ...
def ptx_max_f4(context, builder, sig, args): ...
def ptx_max_f8(context, builder, sig, args): ...
def ptx_min_f4(context, builder, sig, args): ...
def ptx_min_f8(context, builder, sig, args): ...
def ptx_round(context, builder, sig, args): ...
def round_to_impl(context, builder, sig, args): ...
def gen_deg_rad(const): ...

_deg2rad: Incomplete
_rad2deg: Incomplete

def _normalize_indices(context, builder, indty, inds, aryty, valty):
    """
    Convert integer indices into tuple of intp
    """
def _atomic_dispatcher(dispatch_fn): ...
@_atomic_dispatcher
def ptx_atomic_add_tuple(context, builder, dtype, ptr, val): ...
@_atomic_dispatcher
def ptx_atomic_sub(context, builder, dtype, ptr, val): ...
@_atomic_dispatcher
def ptx_atomic_inc(context, builder, dtype, ptr, val): ...
@_atomic_dispatcher
def ptx_atomic_dec(context, builder, dtype, ptr, val): ...
def ptx_atomic_bitwise(stub, op): ...
@_atomic_dispatcher
def ptx_atomic_exch(context, builder, dtype, ptr, val): ...
@_atomic_dispatcher
def ptx_atomic_max(context, builder, dtype, ptr, val): ...
@_atomic_dispatcher
def ptx_atomic_min(context, builder, dtype, ptr, val): ...
@_atomic_dispatcher
def ptx_atomic_nanmax(context, builder, dtype, ptr, val): ...
@_atomic_dispatcher
def ptx_atomic_nanmin(context, builder, dtype, ptr, val): ...
def ptx_atomic_compare_and_swap(context, builder, sig, args): ...
def ptx_atomic_cas(context, builder, sig, args): ...
def ptx_nanosleep(context, builder, sig, args) -> None: ...
def _generic_array(context, builder, shape, dtype, symbol_name, addrspace, can_dynsized: bool = False): ...
def cuda_dispatcher_const(context, builder, ty, pyval): ...
